{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301290e6-12c7-4be9-bbe2-e557964621ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Installing Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ec955fa-2bf3-4ccb-b23f-2f7fcf858669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88bc2770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
      "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.11/dist-packages (1.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
      "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Prerequisites for running the Python script\n",
    "!pip install pandas numpy scikit-learn keras matplotlib seaborn dill keras-tuner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9108f-2e29-4d32-83a7-d89cac267c3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67461354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dropout, Dense, Bidirectional, Attention, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.tuners import BayesianOptimization\n",
    "from kerastuner.engine.hypermodel import HyperModel\n",
    "\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError\n",
    "from keras_tuner.engine import trial as trial_module\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "from keras_tuner.engine.trial import Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8778f5-fd04-40f9-a1eb-4602ffbaaf0f",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a40d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "file_path = 'Data/data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y', errors='coerce')\n",
    "df.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "# Make a copy before preprocessing\n",
    "df_raw = df.copy()\n",
    "\n",
    "# Define the target variable and features\n",
    "numeric_cols = ['Cases', 'tsf', 'mst', 'rh', 'rfm', 'sca']\n",
    "\n",
    "# Convert numeric columns and handle errors\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8d8f6bb-4672-437d-96b2-babd4d4e79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon=2\n",
    "\n",
    "# Lag feature generation from cases\n",
    "def Lag(data, lags):\n",
    "    for lag in lags:\n",
    "        data[f'lag_{lag}'] = data['Cases'].shift(lag)\n",
    "    return data\n",
    "\n",
    "lags = [1, 2, 3, 4, 5, 6] # Specify how many lagged features are used\n",
    "df = Lag(df, lags=lags)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "feature_cols = [f'lag_{lag}' for lag in lags] + ['tsf','mst','rh','rfm','sca'] #Insert the lagged cases into the numeric cols\n",
    "n_features = len(feature_cols) \n",
    "\n",
    "def build_model(hp):\n",
    "    # Pull window from the hyperparameters\n",
    "    window = hp.Int('window', 2, 16, step=1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(window, n_features)))\n",
    "\n",
    "    num_layers = hp.Int('num_layers', 1, 3, 1) #(1,4,1)\n",
    "    for i in range(num_layers):\n",
    "        units      = hp.Int(f'lstm_units_{i}',    64, 512, 32)\n",
    "        rec_drop   = hp.Float(f'rec_dropout_{i}',  0.0, 0.3, 0.05)\n",
    "        return_seq = (i < num_layers - 1)\n",
    "\n",
    "        if hp.Boolean(f'bidirectional_{i}'):\n",
    "            model.add(Bidirectional(LSTM(units,return_sequences=return_seq,recurrent_dropout=rec_drop)))\n",
    "        else:\n",
    "            model.add(LSTM(units,return_sequences=return_seq, recurrent_dropout=rec_drop))\n",
    "\n",
    "        model.add(Dropout(hp.Float(f'dropout_{i}', 0.1, 0.3, 0.05)))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    lr  = hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4, 1e-5])\n",
    "    opt = Adam(learning_rate=lr)\n",
    "\n",
    "    model.compile(optimizer=opt, loss='mse', metrics=['mae', 'mse'])\n",
    "    return model\n",
    "    \n",
    "class Optimize(BayesianOptimization):\n",
    "    '''\n",
    "    Hyperparameters are formatted as (hyperparemter, min, max, steps)\n",
    "    '''\n",
    "    def run_trial(self, trial: Trial, df, features, **fit_kwargs):\n",
    "        window = trial.hyperparameters.Int('window', 2, 16, step=1) # Match the window parameters to the model\n",
    "        batch_size = trial.hyperparameters.Int('batch_size', 32, 128, 16) \n",
    "        epochs     = trial.hyperparameters.Int('epochs',     20, 150, 10)\n",
    "        \n",
    "        # Prepare data per trial\n",
    "        df_proc = df.copy() #Use the copy of the data\n",
    "        df_proc['y_future'] = df_proc['Cases'].shift(-horizon) #Shifting the cases t-horizon days to line up with features in t\n",
    "        df_proc.dropna(subset=['y_future'], inplace=True)\n",
    "        X_loc, y_loc = [], []\n",
    "\n",
    "        #Rolling window\n",
    "        for i in range(window, len(df_proc)-horizon): \n",
    "            X_loc.append(df_proc[features].iloc[i-window:i].values)\n",
    "            y_loc.append(df_proc['y_future'].iloc[i])\n",
    "            \n",
    "        X_loc = np.array(X_loc)\n",
    "        y_loc = np.array(y_loc)\n",
    "        \n",
    "        y_loc_scaled = y_scaler.transform(y_loc.reshape(-1,1)).flatten()\n",
    "\n",
    "        # Sample weights\n",
    "        sw = 1.0 + np.where(y_loc > 0, 5.0, 0.5)\n",
    "        sw_train = sw[:train_end]\n",
    "        sw_val   = sw[train_end:val_end]\n",
    "\n",
    "        # Callbacks\n",
    "        callbacks = [EarlyStopping(monitor='mse', patience=10, restore_best_weights=True)]\n",
    "\n",
    "        # Build and attach scaler\n",
    "        model = build_model(trial.hyperparameters)\n",
    "        model.y_scaler = y_scaler\n",
    "\n",
    "        # 5) Delegate to the parent class\n",
    "        return super().run_trial(\n",
    "            trial,\n",
    "            X_loc[:train_end], y_loc_scaled[:train_end],\n",
    "            validation_data=(X_loc[train_end:val_end], y_loc_scaled[train_end:val_end]),\n",
    "            sample_weight=sw_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            **fit_kwargs\n",
    "        )\n",
    "\n",
    "n_features = len(feature_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "018cda62-c8c1-4bf8-ac32-75b26d5c8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y arrays (again)\n",
    "X, y = [], []\n",
    "for i in range(lags[-1], len(df) - horizon):\n",
    "    X.append(df[feature_cols].iloc[i-lags[-1]:i].values)\n",
    "    y.append(df['Cases'].shift(-horizon).iloc[i])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Scale targets once on the full array, then split\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaled = y_scaler.fit_transform(y.reshape(-1,1)).flatten()\n",
    "\n",
    "# Split into train, val, test (80/10/10)/ This is based on indexing; make sure that data is arranged linearly.\n",
    "n = len(X)\n",
    "train_end = int(0.8 * n)\n",
    "val_end   = int(0.9 * n)\n",
    "\n",
    "x_train, x_val, x_test = X[:train_end], X[train_end:val_end], X[val_end:]\n",
    "y_train, y_val, y_test = (\n",
    "    y_scaled[:train_end],\n",
    "    y_scaled[train_end:val_end],\n",
    "    y_scaled[val_end:]\n",
    ")\n",
    "\n",
    "#Scale the features\n",
    "feature_scaler = MinMaxScaler()\n",
    "df[feature_cols] = feature_scaler.fit_transform(df[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b558e4f-5f20-4a3c-81c0-1807549e63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign weights based on correlation with cases\n",
    "weights = {\n",
    "    col: df[col].corr(df['Cases'])  # or use lagged cases\n",
    "    for col in ['tsf','mst','rh','rfm','sca']\n",
    "}\n",
    "weights_df = pd.DataFrame.from_dict(weights, orient='index', columns=['Weight']).sort_values('Weight')\n",
    "print(\"Feature weights (corr with Cases):\")\n",
    "print(weights_df)\n",
    "\n",
    "weighted = df[numeric_cols].copy()\n",
    "for col, w in weights.items():\n",
    "    weighted[col] = weighted[col] * w\n",
    "corr_matrix = weighted.corr()\n",
    "\n",
    "#Plotting\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(corr_matrix, interpolation='nearest', aspect='auto')\n",
    "plt.colorbar(label='Correlation')\n",
    "plt.xticks(range(len(corr_matrix)), corr_matrix.columns, rotation=45, ha='right')\n",
    "plt.yticks(range(len(corr_matrix)), corr_matrix.index)\n",
    "plt.title(\"Heatmap of Weighted Feature Correlations\")\n",
    "\n",
    "# Add annotations\n",
    "for i in range(corr_matrix.shape[0]):\n",
    "    for j in range(corr_matrix.shape[1]):\n",
    "        plt.text(j, i, f\"{corr_matrix.iloc[i, j]:.2f}\", ha='center', va='center', color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Results/Plots/CorrMatrix.tiff\", dpi=600, format='tiff', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5730a2-13dc-4162-9cd1-8b11c1553e8a",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79d1c1-ccee-4d48-b153-735939a1d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Instantiate the tuner\n",
    "tuner = Optimize(\n",
    "    hypermodel=build_model,\n",
    "    objective='val_loss', #MSE in this case\n",
    "    max_trials=100,\n",
    "    num_initial_points=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='Models',\n",
    "    project_name=f'Horizon({horizon})',\n",
    "    #overwrite=True, #Only activate when Overwriting!\n",
    ")\n",
    "\n",
    "tuner.search(df=df, features=feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d82e9-c81c-4241-ab60-28ec5b21cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "\n",
    "best_hp = best_trial.hyperparameters\n",
    "\n",
    "window = (best_hp.get('window'))\n",
    "best_batch   = best_hp.get('batch_size')\n",
    "best_epochs  = best_hp.get('epochs')\n",
    "\n",
    "num_layers = best_hp.get('num_layers')\n",
    "lstm_units = [best_hp.get(f'lstm_units_{i}') for i in range(num_layers)]\n",
    "dropouts = [best_hp.get(f'dropout_{i}') for i in range(num_layers)]\n",
    "rec_dropouts = [best_hp.get(f'rec_dropout_{i}') for i in range(num_layers)]\n",
    "\n",
    "best_lr  = best_hp.get('learning_rate')\n",
    "\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "best_model.y_scaler = y_scaler\n",
    "\n",
    "print(f\"Horizon: {horizon}\")\n",
    "print(f\"Best window:  {window}\")\n",
    "print(f\"Best batch:  {best_batch}\")\n",
    "print(f\"Best epoch: {best_epochs}\")\n",
    "print(f\"Best learning rate: {best_lr}\")\n",
    "print(f\"Best Num Layers: {num_layers}\")\n",
    "print(f\"LSTM Units: {lstm_units}\")\n",
    "print(f\"Dropouts: {dropouts}\")\n",
    "print(f\"Recurrent dropouts: {rec_dropouts}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
